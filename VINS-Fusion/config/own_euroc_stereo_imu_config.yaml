%YAML:1.0

#common parameters
#support: 1 imu 1 cam; 1 imu 2 cam: 2 cam; 
imu: 0
num_of_cam: 2  

imu_topic: "/imu/data_raw"
image0_topic: "/left_image"
image1_topic: "/right_image"
output_path: "~/output/"

cam0_calib: "own_cam0_pinhole.yaml"
cam1_calib: "own_cam1_pinhole.yaml"

image_width: 640
image_height: 480
   
# Extrinsic parameter between IMU and Camera.
estimate_extrinsic: 1   # 0  Have an accurate extrinsic parameters. We will trust the following imu^R_cam, imu^T_cam, don't change it.
                        # 1  Have an initial guess about extrinsic parameters. We will optimize around your initial guess.

body_T_cam0: !!opencv-matrix # camera in imu coordinate
   rows: 4
   cols: 4
   dt: d
   data: [0.01223976, 0.07822245, 0.99686079, 0.01804841,
           -0.99990993, -0.00453267, 0.01263287, 0.09978829,
            0.00550662, -0.99692563, 0.07815993, -0.0295002,
             0, 0, 0, 1]
   #0.01781426, 0.07168758, 0.99726804, 0.03473806,
   #       -0.99977846, -0.00990679, 0.01857124, 0.09716012,
   #        0.01121105, -0.99737794, 0.07149522, -0.0285895,

body_T_cam1: !!opencv-matrix
   rows: 4
   cols: 4
   dt: d
   data: [0.00970226, 0.09572566, 0.99536047, 0.02159202,
          -0.9999439, 0.00515836, 0.00925085, -0.09655228,
          -0.00424888, -0.99539439, 0.09577033, -0.029753,
          0, 0, 0, 1 ]

  # -0.00791971, 0.08673127, 0.99620026, 0.03724855,
   #       -0.99996816, 0.00028726, -0.00797468, -0.09732044,
    #      -0.00097782, -0.9962317, 0.08672623, -0.02724318,



#cam_T_lidar: !!opencv-matrix
#  rows: 4
#  cols: 4
#  dt: d
#  data: [0.168554, -0.984759, 0.0428744, 0.0,
#         0.0971435, 0.059889, 0.993467, 0.0,
#         -0.980894, -0.163288, 0.105756, 0.0,
#         0.0, 0.0, 0.0, 1.0]


#body_T_cam: !!opencv-matrix
#  rows: 4
#  cols: 4
#  dt: d
#  data:  [-0.01418855, -0.05171673, -0.998561, -0.0465206,
#          0.99989562, 0.00198957, -0.01431056, -0.09290537,
#          0.0027268, -0.99865981, 0.05168311, -0.02565363,
#         0, 0, 0, 1]

#Multiple thread support
multiple_thread: 1

#feature traker paprameters
max_cnt: 200            # max feature number in feature tracking
min_dist: 15            # min distance between two features
freq: 10                # frequence (Hz) of publish tracking result. At least 10Hz for good estimation. If set 0, the frequence will be same as raw image 
F_threshold: 1.0        # ransac threshold (pixel)
show_track: 1           # publish tracking image as topic
flow_back: 1            # perform forward and backward optical flow to improve feature tracking accuracy

#optimization parameters
max_solver_time: 0.04  # max solver itration time (ms), to guarantee real time
max_num_iterations: 8   # max solver itrations, to guarantee real time
keyframe_parallax: 20 # keyframe selection threshold (pixel)

#imu parameters       The more accurate parameters you provide, the better performance
acc_n: 0.1          # accelerometer measurement noise standard deviation. #0.2   0.04
gyr_n: 0.01         # gyroscope measurement noise standard deviation.     #0.05  0.004
acc_w: 0.001         # accelerometer bias random work noise standard deviation.  #0.02
gyr_w: 1.0e-4       # gyroscope bias random work noise standard deviation.     #4.0e-5
g_norm: 9.81007     # gravity magnitude

#unsynchronization parameters
estimate_td: 1                      # online estimate time offset between camera and imu
td: 0.0229                             # initial value of time offset. unit: s. readed image clock + td = real image clock (IMU clock)

#loop closure parameters
load_previous_pose_graph: 0        # load and reuse previous pose graph; load from 'pose_graph_save_path'
pose_graph_save_path: "~/output/pose_graph/" # save and load path
save_image: 1                   # save image in pose graph for visualization prupose; you can close this function by setting 0 

segma: 0.00
